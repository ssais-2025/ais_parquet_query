{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45507065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and loading httpfs extension...\n",
      "✅ DuckDB configured for AWS S3 access in region: il-central-1\n",
      "✅ Using credentials: AKIAQ67NRV...\n",
      "Querying: https://ais-research-data.s3.il-central-1.amazonaws.com/parquet/year%3D2017/month%3D3/day%3D1/01_exactEarth_historical_data_2017-03-01.parquet?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAQ67NRVWQK3FPSR5P%2F20250913%2Fil-central-1%2Fs3%2Faws4_request&X-Amz-Date=20250913T230937Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=289a0459fc168aa5fd16d5518818f3d924adb64bb0ef435476df99cb9080eda7\n",
      "Sample data from S3 parquet file:\n",
      "      base_date_time  year  month  day  hour  minute  second        lon  \\\n",
      "0  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN    13.0 -40.782283   \n",
      "1  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN    54.0 -46.323187   \n",
      "2  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN    51.0 -18.380190   \n",
      "3  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN    42.0 -18.953433   \n",
      "4  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN    15.0 -71.138718   \n",
      "5  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN    55.0 -68.047283   \n",
      "6  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN    23.0 -17.065283   \n",
      "7  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN     5.0 -47.678898   \n",
      "8  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN    30.0 -15.754887   \n",
      "9  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN     5.0  70.515095   \n",
      "\n",
      "         lat       mmsi  ...   vin length  beam  spare  speed_q  course_q  \\\n",
      "0  -2.126833  538090507  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "1 -24.119737  244275000  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "2  65.978828  251006110  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "3 -29.780767  372787000  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "4 -53.861620  725000659  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "5 -68.124155  701829000  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "6 -33.347088  538005909  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "7 -29.967983  566688000  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "8 -38.948630  247298500  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "9 -34.185795  266259000  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "\n",
      "   heading_q  hazard  shiptype  loaded  \n",
      "0       <NA>     NaN       NaN     NaN  \n",
      "1       <NA>     NaN       NaN     NaN  \n",
      "2       <NA>     NaN       NaN     NaN  \n",
      "3       <NA>     NaN       NaN     NaN  \n",
      "4       <NA>     NaN       NaN     NaN  \n",
      "5       <NA>     NaN       NaN     NaN  \n",
      "6       <NA>     NaN       NaN     NaN  \n",
      "7       <NA>     NaN       NaN     NaN  \n",
      "8       <NA>     NaN       NaN     NaN  \n",
      "9       <NA>     NaN       NaN     NaN  \n",
      "\n",
      "[10 rows x 127 columns]\n",
      "\n",
      "DataFrame shape: (10, 127)\n",
      "Columns: ['base_date_time', 'year', 'month', 'day', 'hour', 'minute', 'second', 'lon', 'lat', 'mmsi', 'imo', 'callsign', 'accuracy', 'epfd', 'msg_type', 'repeat', 'status', 'turn', 'speed', 'course', 'heading', 'ais_version', 'maneuver', 'raim', 'radio', 'shipname', 'ship_type', 'to_bow', 'to_stern', 'to_port', 'to_starboard', 'draught', 'destination', 'dte', 'seqno', 'dest_mmsi', 'retransmit', 'dac', 'fid', 'data', 'mmsi1', 'mmsiseq1', 'mmsi2', 'mmsiseq2', 'mmsi3', 'mmsiseq3', 'mmsi4', 'mmsiseq4', 'alt', 'assigned', 'text', 'cs', 'display', 'dsc', 'band', 'type1_1', 'offset1_1', 'type1_2', 'offset1_2', 'type2_1', 'offset2_1', 'offset1', 'increment1', 'offset2', 'increment2', 'msg22', 'number1', 'timeout1', 'number2', 'timeout2', 'offset3', 'number3', 'timeout3', 'increment3', 'offset4', 'number4', 'timeout4', 'increment4', 'd_type', 'name', 'off_position', 'virtual_aid', 'name_ext', 'channel_a', 'channel_b', 'txrx', 'power', 'dest1', 'dest2', 'addressed', 'band_a', 'band_b', 'zonesize', 'ne_lon', 'ne_lat', 'sw_lon', 'sw_lat', 'station_type', 'interval', 'quiet', 'partno', 'vendorid', 'model', 'serial', 'structured', 'gnss', 'aid_type', 'app_id', 'spare_1', 'spare_2', 'spare_3', 'spare_4', 'reserved_1', 'reserved_2', 'empty_1', 'empty_2', 'full_name', 'vin', 'length', 'beam', 'spare', 'speed_q', 'course_q', 'heading_q', 'hazard', 'shiptype', 'loaded']\n",
      "\n",
      "--- Trying without explicit credentials (presigned URL should work) ---\n",
      "Success with presigned URL:\n",
      "      base_date_time  year  month  day  hour  minute  second        lon  \\\n",
      "0  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN    13.0 -40.782283   \n",
      "1  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN    54.0 -46.323187   \n",
      "2  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN    51.0 -18.380190   \n",
      "3  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN    42.0 -18.953433   \n",
      "4  2017/3/1 00:00:00   NaN    NaN  NaN   NaN     NaN    15.0 -71.138718   \n",
      "\n",
      "         lat       mmsi  ...   vin length  beam  spare  speed_q  course_q  \\\n",
      "0  -2.126833  538090507  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "1 -24.119737  244275000  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "2  65.978828  251006110  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "3 -29.780767  372787000  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "4 -53.861620  725000659  ...  None    NaN   NaN   <NA>     <NA>      <NA>   \n",
      "\n",
      "   heading_q  hazard  shiptype  loaded  \n",
      "0       <NA>     NaN       NaN     NaN  \n",
      "1       <NA>     NaN       NaN     NaN  \n",
      "2       <NA>     NaN       NaN     NaN  \n",
      "3       <NA>     NaN       NaN     NaN  \n",
      "4       <NA>     NaN       NaN     NaN  \n",
      "\n",
      "[5 rows x 127 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Querying Parquet Files from S3\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Method 1: Using DuckDB to query parquet files directly from S3\n",
    "# DuckDB has built-in S3 support and can query parquet files directly from S3 URLs\n",
    "\n",
    "# Connect to DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Install and load httpfs extension for S3 support\n",
    "print(\"Installing and loading httpfs extension...\")\n",
    "con.execute(\"INSTALL httpfs\")\n",
    "con.execute(\"LOAD httpfs\")\n",
    "\n",
    "# Configure DuckDB with AWS credentials and region\n",
    "# Get credentials from environment variables\n",
    "aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "aws_region = os.getenv('AWS_DEFAULT_REGION', 'il-central-1')\n",
    "\n",
    "if aws_access_key and aws_secret_key:\n",
    "    con.execute(f\"SET s3_region='{aws_region}'\")\n",
    "    con.execute(f\"SET s3_access_key_id='{aws_access_key}'\")\n",
    "    con.execute(f\"SET s3_secret_access_key='{aws_secret_key}'\")\n",
    "    print(f\"✅ DuckDB configured for AWS S3 access in region: {aws_region}\")\n",
    "    print(f\"✅ Using credentials: {aws_access_key[:10]}...\")\n",
    "else:\n",
    "    print(\"⚠️ AWS credentials not found in environment variables\")\n",
    "    print(\" Run: source .env\")\n",
    "\n",
    "# Presigned URL for the parquet file\n",
    "s3_presigned_url = \"https://ais-research-data.s3.il-central-1.amazonaws.com/parquet/year%3D2017/month%3D3/day%3D1/01_exactEarth_historical_data_2017-03-01.parquet?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAQ67NRVWQK3FPSR5P%2F20250913%2Fil-central-1%2Fs3%2Faws4_request&X-Amz-Date=20250913T230937Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=289a0459fc168aa5fd16d5518818f3d924adb64bb0ef435476df99cb9080eda7\"\n",
    "\n",
    "# Query the parquet file from S3\n",
    "try:\n",
    "    print(f\"Querying: {s3_presigned_url}\")\n",
    "    # Fixed: Use the correct variable name\n",
    "    result = con.execute(f\"SELECT * FROM '{s3_presigned_url}' LIMIT 10\").fetchdf()\n",
    "    print(\"Sample data from S3 parquet file:\")\n",
    "    print(result)\n",
    "    print(f\"\\nDataFrame shape: {result.shape}\")\n",
    "    print(f\"Columns: {list(result.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error querying S3 parquet file: {e}\")\n",
    "    print(\"Make sure your AWS credentials are configured and the S3 URL is correct\")\n",
    "\n",
    "# Alternative: If you don't need AWS credentials (since you have a presigned URL)\n",
    "# You can try without setting credentials\n",
    "try:\n",
    "    print(\"\\n--- Trying without explicit credentials (presigned URL should work) ---\")\n",
    "    con_simple = duckdb.connect()\n",
    "    con_simple.execute(\"INSTALL httpfs\")\n",
    "    con_simple.execute(\"LOAD httpfs\")\n",
    "    \n",
    "    result2 = con_simple.execute(f\"SELECT * FROM '{s3_presigned_url}' LIMIT 5\").fetchdf()\n",
    "    print(\"Success with presigned URL:\")\n",
    "    print(result2)\n",
    "except Exception as e:\n",
    "    print(f\"Error with presigned URL approach: {e}\")\n",
    "\n",
    "# Close connections\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c5ae0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Querying Parquet Files from S3\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Method 1: Using DuckDB to query parquet files directly from S3\n",
    "# DuckDB has built-in S3 support and can query parquet files directly from S3 URLs\n",
    "\n",
    "# Connect to DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Install and load httpfs extension for S3 support\n",
    "print(\"Installing and loading httpfs extension...\")\n",
    "con.execute(\"INSTALL httpfs\")\n",
    "con.execute(\"LOAD httpfs\")\n",
    "\n",
    "# Configure DuckDB with AWS credentials and region\n",
    "# Get credentials from environment variables\n",
    "aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "aws_region = os.getenv('AWS_DEFAULT_REGION', 'il-central-1')\n",
    "\n",
    "if aws_access_key and aws_secret_key:\n",
    "    con.execute(f\"SET s3_region='{aws_region}'\")\n",
    "    con.execute(f\"SET s3_access_key_id='{aws_access_key}'\")\n",
    "    con.execute(f\"SET s3_secret_access_key='{aws_secret_key}'\")\n",
    "    print(f\"✅ DuckDB configured for AWS S3 access in region: {aws_region}\")\n",
    "    print(f\"✅ Using credentials: {aws_access_key[:10]}...\")\n",
    "else:\n",
    "    print(\"⚠️ AWS credentials not found in environment variables\")\n",
    "    print(\" Run: source .env\")\n",
    "\n",
    "# Presigned URL for the parquet file\n",
    "s3_presigned_url = \"https://ais-research-data.s3.il-central-1.amazonaws.com/parquet/year%3D2017/month%3D3/day%3D1/01_exactEarth_historical_data_2017-03-01.parquet?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAQ67NRVWQK3FPSR5P%2F20250913%2Fil-central-1%2Fs3%2Faws4_request&X-Amz-Date=20250913T230937Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=289a0459fc168aa5fd16d5518818f3d924adb64bb0ef435476df99cb9080eda7\"\n",
    "\n",
    "# Query the parquet file from S3\n",
    "try:\n",
    "    print(f\"Querying: {s3_presigned_url}\")\n",
    "    # Fixed: Use the correct variable name\n",
    "    result = con.execute(f\"SELECT * FROM '{s3_presigned_url}' LIMIT 10\").fetchdf()\n",
    "    print(\"Sample data from S3 parquet file:\")\n",
    "    print(result)\n",
    "    print(f\"\\nDataFrame shape: {result.shape}\")\n",
    "    print(f\"Columns: {list(result.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error querying S3 parquet file: {e}\")\n",
    "    print(\"Make sure your AWS credentials are configured and the S3 URL is correct\")\n",
    "\n",
    "# Alternative: If you don't need AWS credentials (since you have a presigned URL)\n",
    "# You can try without setting credentials\n",
    "try:\n",
    "    print(\"\\n--- Trying without explicit credentials (presigned URL should work) ---\")\n",
    "    con_simple = duckdb.connect()\n",
    "    con_simple.execute(\"INSTALL httpfs\")\n",
    "    con_simple.execute(\"LOAD httpfs\")\n",
    "    \n",
    "    result2 = con_simple.execute(f\"SELECT * FROM '{s3_presigned_url}' LIMIT 5\").fetchdf()\n",
    "    print(\"Success with presigned URL:\")\n",
    "    print(result2)\n",
    "except Exception as e:\n",
    "    print(f\"Error with presigned URL approach: {e}\")\n",
    "\n",
    "# Close connections\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8824a8cb-aad9-45cc-8d22-0631a002382b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and loading httpfs extension...\n",
      "✅ DuckDB configured for AWS S3 access in region: il-central-1\n",
      "✅ Using credentials: AKIAQ67NRV...\n",
      "Querying: s3://ais-research-data/parquet/year=2017/month=3/day=1/01_exactEarth_historical_data_2017-03-01.parquet\n",
      "Error querying S3 parquet file: HTTP Error: HTTP GET error on 'https://ais-research-data.s3.amazonaws.com/parquet/year%3D2017/month%3D3/day%3D1/01_exactEarth_historical_data_2017-03-01.parquet' (HTTP 400)\n",
      "\n",
      "Bad Request - this can be caused by the S3 region being set incorrectly.\n",
      "* Provided region is \"il-central-1\"\n",
      "Make sure your AWS credentials are configured and the S3 URL is correct\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe0442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b05a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60c3575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af0678-7954-4853-80c9-4042fb134abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e125b-c5b5-4a48-8e36-cad0e04077f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bba354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54958825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dd2ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b51779d0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIS Parquet Query",
   "language": "python",
   "name": "ais_parquet_query"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
